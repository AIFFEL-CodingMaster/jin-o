{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./preprocessing2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./preprocessing2.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# mat삭제\n",
    "def delete_mat(data_list):\n",
    "    for i, data in enumerate(data_list):\n",
    "        print(data)\n",
    "        basename = os.path.basename(data)\n",
    "        # os.path.basename 입력받은 경로의 기본이름을 반환 >> 경로중 파일명만 얻기\n",
    "        \n",
    "        _, file = basename.split(\".\")\n",
    "        \n",
    "        if file == \"mat\":\n",
    "            del data_list[i]\n",
    "    return data_list\n",
    "\n",
    "# 4channel 삭제\n",
    "def delete_4_channel(data_list):\n",
    "    for i, data in enumerate(data_list):\n",
    "        image_data = Image.open(data)\n",
    "        mode = image_data.mode\n",
    "        \n",
    "        if mode != \"RGB\":\n",
    "            del data_list[i]\n",
    "    return data_list\n",
    "\n",
    "# 라벨 인코딩\n",
    "def label_encoding(data_list):\n",
    "    # 방법1\n",
    "    class_list = []\n",
    "    for data in data_list:\n",
    "        basename = os.path.basename(data) \n",
    "        label = os.path.splitext(basename)[0] # 파일명에서 확장자만 따로 분리됨\n",
    "        label = re.sub(\"_\\d+\",\"\",label)  #숫자를 공백으로?\n",
    "        \n",
    "        if label in class_list:\n",
    "            continue\n",
    "        else:\n",
    "            class_list.append(label)\n",
    "            \n",
    "    class_to_index = {cls:i for i, cls in enumerate(class_list)} # 이름:인덱스 형태의 dict생성?\n",
    "    return class_to_index\n",
    "            \n",
    "## label 숫자제거시 기존 이름과 중복될경우는?  car1, car2작업시    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./tf_record2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./tf_record2.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "class MakeTFRecord:\n",
    "    \n",
    "    IMG_SIZE = 224\n",
    "    \n",
    "    def __init__(self, data_list, tfr_path, data_class):\n",
    "        self.data_list = data_list\n",
    "        self.tfr_path = tfr_path\n",
    "        self.data_class = data_class\n",
    "        \n",
    "    def _make_tf_writer(self):\n",
    "        '''\n",
    "        TF writer를 만드는 tf함수\n",
    "        '''\n",
    "        writer = tf.io.TFRecordWriter(self.tfr_path)\n",
    "        return writer\n",
    "    \n",
    "    #  The following functions can be used to convert a value to a type compatible\n",
    "    # with tf.Example >> 값을 호환가능한 유형으로 변환 가능\n",
    "    @staticmethod\n",
    "    # 클래스에서 바로 접근가능, self인자 없음\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            # value가 상수이면?\n",
    "            value = value.numpy() # bytelist won't unpack a string from an EagerTensor\n",
    "        return tf.train.Feature(bytes_list=tf.train.ByteList(value=[value])) # tf.train.ByteList - string, byte값으로부터 mapping\n",
    "                                \n",
    "    @staticmethod\n",
    "    def _float_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.Floatlist(value=[value])) # float(32), double(float64)값으로부터 mapping\n",
    "    \n",
    "    @staticmethod\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list = tf.train.Int64List(value=[value]))\n",
    "                                \n",
    "    def _make_tfrecord(self):\n",
    "        writer = self._make_tf_writer()\n",
    "        n = 0\n",
    "        \n",
    "        for data in self.data_list:\n",
    "            image = Image.open(data)\n",
    "            image = image.resize((self.IMG_SIZE, self.IMG_SIZE)) # 가로(width) 세로(height)\n",
    "            # tf record byte로 되어있음\n",
    "            image_to_byte = image.tobyte()\n",
    "            \n",
    "            basename = os.path.basename(data)\n",
    "            label = os.path.split(basename)[0]\n",
    "            label = re.sub(\"_\\d+\", \"\", label)\n",
    "            label_num = self.data_class[label]\n",
    "            # tf.train.Example객체 생성후 인자로 features에 TFRecord에 저장될 값의 목록을 dict로 저장\n",
    "            example = tf.train.Example(features=tf.train.Features(features={\n",
    "                \"image\" : self._bytes_feature(image_to_byte),\n",
    "                \"label\" : self._int64_feature(label_num)\n",
    "            }))\n",
    "                                \n",
    "            writer.write(example.SerializeToString())\n",
    "            # 데이터를 tf.train.Feature로 변환후 tf.Example 정의 후,SerializeToString()이용 직렬화\n",
    "            n += 1\n",
    "        writer.close()\n",
    "        print(f\"{n}개의 데이터, TFRecord완성\")\n",
    "                                \n",
    "    @classmethod # cls라는 인자 필요\n",
    "    def change_img_size(cls, image_size):\n",
    "        cls.IMG_SIZE = image_size\n",
    "    \n",
    "    # class의 인스턴스를 함수처럼 호출가능\n",
    "    def __call__(self): \n",
    "        print(\"tfrecord 만들기 시작\")\n",
    "        self._make_tfrecord()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dataloader2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./dataloader2.py\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "class TFRecordLoader:\n",
    "    \n",
    "    def __init__(self, tf_record_path, img_size, n_class, train_size_rate, batch_size):\n",
    "        self.tfrecord = tfrecord_path\n",
    "        self.img_size = img_szie\n",
    "        self.n_class = n_class\n",
    "        self.train_szie_rate = train_size_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    ## tfrecord file을 data로 parsing\n",
    "    def _parse_function(self, tfrecord_serialized):\n",
    "        features = {'image' : tf.io.FixedLenFeature([], tf.string),\n",
    "                   'label' : tf.io.FixedLenFeature([], tf.int64)}\n",
    "        parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "        \n",
    "        image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "        image = tf.reshape(image, [self.img_size, self.img_size, 3])\n",
    "        # iamge = tf.cast(image, tf.float32)/255.\n",
    "        \n",
    "        label = tf.cast(parsed_features['label'], tf.int64)\n",
    "        label = tf.one_hot(label, self.n_class)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def make_dataset(self):\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(self.tfrecord)\n",
    "        dataset = dataset.map(\n",
    "            self._parse_function, \n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "                    )\n",
    "        \n",
    "        train_size = int(float(self.train_size_rate * len(list(dataset))))\n",
    "        val_size = int(float((1 - self.train_size_rate) * len(list(dataset))))\n",
    "\n",
    "        buffer_size = len(list(dataset))\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "\n",
    "        train = dataset.take(train_size)\n",
    "        train = train.batch(self.batch_size)\n",
    "        train = train.repeat()\n",
    "        train = train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        # 수정 필요\n",
    "        # train dataset 만큼 스킵\n",
    "        dataset = dataset.skip(train_size)\n",
    "        # validation 크기만큼 데이터를 가져옴\n",
    "        valid = dataset.take(val_size)\n",
    "        # batch dataset으로 만들기\n",
    "        valid = valid.batch(self.batch_size)\n",
    "\n",
    "        steps = math.floor(buffer_size / self.batch_size)\n",
    "\n",
    "        return train, valid, steps \n",
    "\n",
    "    def __call__(self):\n",
    "        return self.make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main2.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tf_record2 import MakeTFRecord\n",
    "from preprocessing2 import delete_mat, delete_4_channel, label_encoding\n",
    "\n",
    "def preprocessing_1(data_path):\n",
    "    date_path = data_path + \"*\"\n",
    "    data_list = glob(data_path)\n",
    "    \n",
    "    # 전처리\n",
    "    data_list = delete_mat(data_list)\n",
    "    data_list = delete_4_channel(data_list)\n",
    "    \n",
    "    data_class = label_encoding(data_list)\n",
    "    return data_list, data_class\n",
    "\n",
    "# __name__ :  해당모듈의 이름 출력\n",
    "#argparse : 사용법메시지 출력?\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=['tfr', 'train', 'test'], help=\"TFRecord 만들기 or 모델 학습 or 모델 테스트\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"./\", help=\"데이터가 들어있는 디렉토리 경로\")\n",
    "    parser.add_argument(\"--tfr_path\", type=str, default=\"./\", help=\"tfrecord가 저장될 디렉토리\")\n",
    "    parser.add_argument(\"--img_size\", type=int, default=224, help=\"이미지 사이즈 입력\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.mode == 'tfr':\n",
    "        data_list, data_class = preprocessing_1(args.data_path)\n",
    "        \n",
    "        IMG_size = args.img_size\n",
    "        tfrecord = MakeTFRecord(data_list = data_list,\n",
    "                               tfr_path = args.tfr_path,\n",
    "                               data_class = data_class)\n",
    "        \n",
    "        if args.img_size !=224:\n",
    "            tf.record.change_img_size(args.img_size)\n",
    "            \n",
    "        #tf record 만들기\n",
    "        tfrecord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac26'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"main2.py\", line 31, in <module>\r\n",
      "    data_list, data_class = preprocessing_1(args.data_path)\r\n",
      "  File \"main2.py\", line 14, in preprocessing_1\r\n",
      "    data_list = delete_mat(data_list)\r\n",
      "  File \"/home/ssac26/workplace/coding_master/prac/preprocessing2.py\", line 13, in delete_mat\r\n",
      "    _, file = basename.split(\".\")\r\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\r\n"
     ]
    }
   ],
   "source": [
    "# let's test\n",
    "import os\n",
    "path_1 = os.getenv('HOME')+'/workplace/coding_master/visions/images/'\n",
    "!python main2.py \\\n",
    "--mode='tfr' \\\n",
    "#--data_path='../visions/images/' \\\n",
    "--data_path=path_1 \\\n",
    "--tfr_path='./tfrecord_data2.tfr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac26/workplace/coding_master/prac'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ssac26/workplace/coding_master/prac'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
